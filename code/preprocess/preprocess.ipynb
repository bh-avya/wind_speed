{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd4af091",
   "metadata": {},
   "source": [
    "# Separate the data for each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5183277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# File paths\n",
    "raw_file = '../../data/raw/ds.xlsx'  \n",
    "raw_folder = '../../data/raw/'\n",
    "processed_folder = '../../data/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3df2a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 'chennai' as '../../data/raw/chennai.csv'\n",
      "Saved 'madurai' as '../../data/raw/madurai.csv'\n",
      "Saved 'salem' as '../../data/raw/salem.csv'\n",
      "Saved 'tirunelveli' as '../../data/raw/tirunelveli.csv'\n",
      "Saved 'coimbatore' as '../../data/raw/coimbatore.csv'\n"
     ]
    }
   ],
   "source": [
    "# Load all sheet names\n",
    "sheet_names = pd.ExcelFile(raw_file).sheet_names\n",
    "\n",
    "# Loop through each sheet and save it as a CSV\n",
    "for sheet in sheet_names:\n",
    "    df = pd.read_excel(raw_file, sheet_name=sheet)\n",
    "    csv_file = os.path.join(raw_folder, f\"{sheet}.csv\")\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    print(f\"Saved '{sheet}' as '{csv_file}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542e5a60",
   "metadata": {},
   "source": [
    "# Chennai Data Pre-processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d314bfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ph/3xpsb48s7r1b8jgwc0wxc0b80000gn/T/ipykernel_42888/2329568619.py:9: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_path, header=None, names=['date', 'wind_speed'])\n",
      "/var/folders/ph/3xpsb48s7r1b8jgwc0wxc0b80000gn/T/ipykernel_42888/2329568619.py:12: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['date'] = pd.to_datetime(df['date'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chennai processed data saved\n"
     ]
    }
   ],
   "source": [
    "# Path to the CSV\n",
    "file_name = 'chennai.csv'\n",
    "input_path = os.path.join(raw_folder, file_name)\n",
    "output_path = os.path.join(processed_folder, file_name)\n",
    "\n",
    "# Load dataset with no headers\n",
    "df = pd.read_csv(input_path, header=None, names=['date', 'wind_speed'])\n",
    "\n",
    "# Drop rows with missing values\n",
    "initial_len = len(df)\n",
    "df.dropna(subset=['date_time', 'wind_speed'], inplace=True)\n",
    "dropped = initial_len - len(df)\n",
    "print(f\"  → Dropped {dropped} null rows\")\n",
    "\n",
    "# Convert date column to datetime\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "# Add hour component (0–23) and convert to ISO format\n",
    "df['hour'] = df.groupby('date').cumcount()\n",
    "df['date_time'] = df['date'] + pd.to_timedelta(df['hour'], unit='h')\n",
    "\n",
    "# Convert wind_speed to float for consistency\n",
    "df['wind_speed'] = pd.to_numeric(df['wind_speed'], errors='coerce').round(2)\n",
    "\n",
    "#Renaming the columns\n",
    "df = df[['date_time', 'wind_speed']]\n",
    "\n",
    "# Ensure ISO 8601 format (you can confirm visually or when saving)\n",
    "df['date_time'] = df['date_time'].dt.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "# Reset the index\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Save the processed DataFrame to a new CSV file\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Chennai processed data saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee519b5a",
   "metadata": {},
   "source": [
    "# Data Pre-processing for Remaining Cities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e5ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: coimbatore.csv\n",
      "  → Dropped 0 null rows\n",
      "  → Saved cleaned file to: ../../data/processed/coimbatore.csv\n",
      "\n",
      "Processing: madurai.csv\n",
      "  → Dropped 0 null rows\n",
      "  → Saved cleaned file to: ../../data/processed/madurai.csv\n",
      "\n",
      "Processing: salem.csv\n",
      "  → Dropped 0 null rows\n",
      "  → Saved cleaned file to: ../../data/processed/salem.csv\n",
      "\n",
      "Processing: tirunelveli.csv\n",
      "  → Dropped 0 null rows\n",
      "  → Saved cleaned file to: ../../data/processed/tirunelveli.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_files = ['coimbatore.csv', 'madurai.csv', 'salem.csv', 'tirunelveli.csv']\n",
    "\n",
    "for file_name in csv_files:\n",
    "    input_path = os.path.join(raw_folder, file_name)\n",
    "    output_path = os.path.join(processed_folder, file_name)\n",
    "\n",
    "    print(f\"Processing: {file_name}\")\n",
    "\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(input_path)\n",
    "\n",
    "    # Rename columns\n",
    "    df.rename(columns={'Date/time [UTC]': 'date_time','Speed_50m [m/s]': 'wind_speed'}, inplace=True)\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    initial_len = len(df)\n",
    "    df.dropna(subset=['date_time', 'wind_speed'], inplace=True)\n",
    "    dropped = initial_len - len(df)\n",
    "    print(f\"  → Dropped {dropped} null rows\")\n",
    "\n",
    "    # Convert types\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'], errors='coerce')\n",
    "    df['wind_speed'] = pd.to_numeric(df['wind_speed'], errors='coerce').round(2)\n",
    "\n",
    "    # Drop rows where parsing failed\n",
    "    df.dropna(subset=['date_time', 'wind_speed'], inplace=True)\n",
    "\n",
    "    # Reset index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Save cleaned file\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"  → Saved cleaned file to: {output_path}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WindSpeed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
